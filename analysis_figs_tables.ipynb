{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "from vis import (\n",
    "    plot_top_bottom_evolution, \n",
    "    table_generator_three_way, \n",
    "    table_generator_two_way, \n",
    "    table_generator_three_way_bloom,\n",
    "    table_generator_two_way_bloom\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IE Evolution of Top-5 and Bottom-5 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_top_bottom_evolution(\n",
    "    version_num   = 446,\n",
    "    max_examples  = 3469,\n",
    "    node_threshold= 0.1,\n",
    "    task          = \"subjectverb\",\n",
    "    ckpt_num      = 20,\n",
    "    top_k         = 5,\n",
    "    ckpt_tokens   = ['1B', '4B', '286B'],\n",
    "    figsize       = (6,16),\n",
    "    save_path     = \"figs/ie_evolution/top5_bottom5_pythia.pdf\",\n",
    "    fontsize      = 28,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_top_bottom_evolution(\n",
    "    version_num   = 447,\n",
    "    max_examples  = 3469,\n",
    "    node_threshold= 0.1,\n",
    "    task          = \"subjectverb\",\n",
    "    ckpt_num      = 20,\n",
    "    top_k         = 5,\n",
    "    ckpt_tokens   = ['4B', '33B', '3T'],\n",
    "    figsize       = (8,14),\n",
    "    save_path     = \"figs/ie_evolution/top5_bottom5_olmo.pdf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pythia Top-10 & Top-100 3D plot of RelIE in 3-way comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version_num = 446\n",
    "base_dir = \"./workspace/logs/ie_dicts_zeroshot\"\n",
    "save_dir = f\"{base_dir}/version_{version_num}\"\n",
    "node_threshold = 0.1\n",
    "ckpt_num = 20\n",
    "max_examples = 3469\n",
    "task = \"subjectverb\"\n",
    "\n",
    "for top_k in [10, 100]:\n",
    "    csv_path = f\"{save_dir}/latents_{task}_ckpt{ckpt_num}_thresh{node_threshold}_n{max_examples}_topk{top_k}.csv\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df['rel_ie_array'] = df['rel_ie_value'].str.strip('[]') \\\n",
    "                                        .apply(lambda s: np.fromstring(s, sep=' '))\n",
    "    \n",
    "    coords = np.vstack(df['rel_ie_array'].values)\n",
    "    x, y, z = coords[:,0], coords[:,1], coords[:,2]\n",
    "\n",
    "    # (elev, azim) pairs\n",
    "    views = [\n",
    "        (20,  30),   # front-angle\n",
    "        (20, 120),   # side-ish\n",
    "        (90,  -90),  # top-view\n",
    "    ]\n",
    "\n",
    "    for elev, azim in views:\n",
    "        fig = plt.figure(constrained_layout=True)\n",
    "        ax  = fig.add_subplot(111, projection='3d')\n",
    "        \n",
    "        # split at .3 and .7 => bins 0:[0 – .3], 1:(.3 – .7], 2:(.7 – 1]\n",
    "        xb = np.digitize(x, [0.3, 0.7])\n",
    "        yb = np.digitize(y, [0.3, 0.7])\n",
    "        zb = np.digitize(z, [0.3, 0.7])\n",
    "\n",
    "        # 2) map low=>0, mid=>.5, high=>1 into RGB channels\n",
    "        r = xb / 2.0      # 0=>0, 1=>.5,   2=>1.0\n",
    "        g = yb / 2.0\n",
    "        b = zb / 2.0\n",
    "        colors = np.stack([r, g, b], axis=1)\n",
    "\n",
    "        # 3) scatter with those colors\n",
    "        ax.scatter(x, y, z, c=colors, marker='o', s=20, edgecolor='k', linewidth=0.2)\n",
    "        \n",
    "        ax.set_xlabel('RelIE 1B')\n",
    "        ax.set_ylabel('RelIE 4B')\n",
    "        ax.set_zlabel('RelIE 286B')\n",
    "        ax.set_xlim(0,1)\n",
    "        ax.set_ylim(0,1)\n",
    "        ax.set_zlim(0,1)        \n",
    "\n",
    "        # smaller pad for the title itself\n",
    "        ax.set_title(\n",
    "            f'Pythia 3-Way Comparison RelIE for TopK={top_k}',\n",
    "            pad=0\n",
    "        )\n",
    "\n",
    "        # tighten margins\n",
    "        # fig.tight_layout(pad=0.25)\n",
    "        \n",
    "        legend_elements = [\n",
    "            Line2D([0], [0],\n",
    "                marker='o', color='w',\n",
    "                markerfacecolor=(1,0,0), markersize=8,\n",
    "                label='RelIE 1B high (x > 0.7)'),\n",
    "            Line2D([0], [0],\n",
    "                marker='o', color='w',\n",
    "                markerfacecolor=(0,1,0), markersize=8,\n",
    "                label='RelIE 4B high (y > 0.7)'),\n",
    "            Line2D([0], [0],\n",
    "                marker='o', color='w',\n",
    "                markerfacecolor=(0,0,1), markersize=8,\n",
    "                label='RelIE 286B high (z > 0.7)'),\n",
    "        ]\n",
    "        \n",
    "        ax.legend(\n",
    "            handles=legend_elements,\n",
    "            title='Channel = high bin',\n",
    "            loc='upper left',             # legend “corner” anchored to:\n",
    "            bbox_to_anchor=(1.05, 1.0),   # (x, y) in axis‐fraction coords\n",
    "            borderaxespad=0.,             # pad between axes and legend\n",
    "        )\n",
    "\n",
    "        ax.view_init(elev=elev, azim=azim)\n",
    "        full_path = f\"figs/pyhtia1b_3compar_RelIE_topk{top_k}_elev{elev}_azim{azim}_full.png\",\n",
    "        crop_path = f\"figs/pyhtia1b_3compar_RelIE_topk{top_k}_elev{elev}_azim{azim}_cropped.png\",\n",
    "        fig.savefig(\n",
    "            f\"figs/pyhtia1b_3compar_RelIE_topk{top_k}_elev{elev}_azim{azim}.png\",\n",
    "            pad_inches=0.0\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLOOM MultiBLiMP Overlap Multilinguality Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_overlap_across_tasks_2way(\n",
    "        task_list,\n",
    "        version_num, \n",
    "        max_examples,\n",
    "        submod_layer,\n",
    "        node_threshold=0.1, \n",
    "        ckpt_num=20, \n",
    "        top_k=100\n",
    "    ):\n",
    "    lang2fidset = {}\n",
    "    lang2relie = {}\n",
    "    fid2relie = {}\n",
    "    fid2reldec = {}\n",
    "        \n",
    "    # (1) for all tasks in task_list\n",
    "    for task in task_list:\n",
    "        # (1.1) Load IE & Rel IE for all tasks in task_list\n",
    "        base_dir = \"./workspace/logs/ie_dicts_zeroshot\"\n",
    "        save_dir = f\"{base_dir}/{version_num}\"\n",
    "        final_path = f\"{save_dir}/{task}_ckpt{ckpt_num}_thresh{node_threshold}_n{max_examples}.pt\"\n",
    "        effects = torch.load(final_path)\n",
    "        \n",
    "        # (1.2) Make a dict of task -> feat_id set\n",
    "        csv_path = f\"{save_dir}/latents_{task}_ckpt{ckpt_num}_thresh{node_threshold}_n{max_examples}_topk10.csv\"\n",
    "        featdf = pd.read_csv(csv_path)\n",
    "        lang = task.split(\"_\")[1]\n",
    "        fid2relie.update(dict(zip(f\"{lang}-\" + str(featdf['feat_id']), featdf['rel_ie_class'])))\n",
    "        fid2reldec.update(dict(zip(f\"{lang}-\" + str(featdf['feat_id']), featdf['rel_dec_norm_class'])))\n",
    "          \n",
    "        all_top100_fids = set(\n",
    "            torch.topk(effects[f\"m1_layer{submod_layer}_out\"].abs(), k=top_k).indices.tolist()\n",
    "            + torch.topk(effects[f\"m2_layer{submod_layer}_out\"].abs(), k=top_k).indices.tolist()\n",
    "        )\n",
    "        print(f\"# of feats for both models for {task}: \", len(all_top100_fids))\n",
    "        \n",
    "        lang2fidset[lang] = all_top100_fids\n",
    "        \n",
    "        \n",
    "    fid2langset = defaultdict(set)\n",
    "    for lang, fidset in lang2fidset.items():\n",
    "        for fid in fidset:\n",
    "            fid2langset[fid].add(lang)\n",
    "    \n",
    "    fid2multilangscore = {}\n",
    "    for fid, langset in fid2langset.items():\n",
    "        fid2multilangscore[fid] = len(langset)\n",
    "            \n",
    "    multilangscore_mean = np.array([len(langset) for fid, langset in fid2langset.items()]).mean()\n",
    "    # print(\"Mean: \", multilangscore_mean)\n",
    "    multilangscore_std = np.array([len(langset) for fid, langset in fid2langset.items()]).std()\n",
    "    # print(\"Std: \", multilangscore_std)\n",
    "\n",
    "    comparison = featdf[\"comparison\"].unique().tolist()[0]\n",
    "    \n",
    "    return lang2fidset, comparison\n",
    "\n",
    "def make_overlap_df(lang2fid, normalize=True):\n",
    "    langs = sorted(lang2fid)\n",
    "    if \"fra\" in langs:\n",
    "        langs = [\"arb\", \"hin\", \"fra\", \"eng\", \"spa\", \"por\"]\n",
    "    else:\n",
    "        langs = [\"arb\", \"hin\", \"por\"]\n",
    "    mat = np.zeros((len(langs), len(langs)), dtype=float)\n",
    "    for i, la in enumerate(langs):\n",
    "        for j, lb in enumerate(langs):\n",
    "            inter = lang2fid[la] & lang2fid[lb]\n",
    "            if normalize:\n",
    "                union = lang2fid[la] | lang2fid[lb]\n",
    "                mat[i, j] = len(inter) / len(union) if union else 0.0\n",
    "            else:\n",
    "                mat[i, j] = len(inter)\n",
    "    return pd.DataFrame(mat, index=langs, columns=langs)\n",
    "\n",
    "def plot_heatmap(df, title=None, save_path=None, fontsize=16):\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    im = ax.imshow(df.values, aspect='equal')\n",
    "    ax.set_xticks(range(len(df.columns)))\n",
    "    ax.set_xticklabels(df.columns, rotation=45, ha='right', fontsize=fontsize)\n",
    "    ax.set_yticks(range(len(df.index)))\n",
    "    ax.set_yticklabels(df.index, fontsize=fontsize)\n",
    "    cbar = fig.colorbar(im, ax=ax)\n",
    "    cbar.set_label('Feature count')\n",
    "    thresh = df.values.max() / 2.0\n",
    "    for i in range(len(df)):\n",
    "        for j in range(len(df)):\n",
    "            val = df.values[i, j]\n",
    "            text_color = \"white\" if val < thresh else \"black\"\n",
    "            ax.text(\n",
    "                j, i, f\"{int(val)}\",\n",
    "                ha='center', va='center',\n",
    "                color=text_color,\n",
    "                fontsize=fontsize\n",
    "            )\n",
    "    if title:\n",
    "        ax.set_title(title, fontsize=fontsize + 2)\n",
    "    plt.tight_layout()\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "langs=[\"eng\", \"fra\", \"spa\", \"por\", \"arb\", \"hin\"]\n",
    "svg_langs=[\"por\", \"arb\", \"hin\"]\n",
    "\n",
    "tasks=[\"SV-#\", \"SV-G\", \"SV-P\"]\n",
    "task2len = {\n",
    "    \"SV-#\": 100,\n",
    "    \"SV-G\": 100, \n",
    "    \"SV-P\": 290\n",
    "}\n",
    "\n",
    "for top_k in [10, 100]:\n",
    "    for task in tasks:\n",
    "        print(\"#\" * 40)\n",
    "        print(\"task: \", task)\n",
    "        for version_num in [\"387\",  \"400\", \"409\"]:\n",
    "            print(\"-\" * 20)\n",
    "            print(\"version_num: \", version_num)\n",
    "            task_list = []\n",
    "            if task == \"SV-G\":\n",
    "                task_list = [f\"multiblimp_{lang}_{task}\" for lang in svg_langs]\n",
    "            else:\n",
    "                task_list = [f\"multiblimp_{lang}_{task}\" for lang in langs]\n",
    "            lang2fid, comparison = get_feature_overlap_across_tasks_2way(\n",
    "                task_list=task_list,\n",
    "                version_num=\"version_\" + version_num,\n",
    "                max_examples=task2len[task],\n",
    "                submod_layer=12,\n",
    "                top_k=top_k\n",
    "            )\n",
    "            \n",
    "            overlap_df = make_overlap_df(lang2fid, normalize=False)\n",
    "            final_path = f\"figs/multilingual_overlap_2way/multilang_overlap_topk{top_k}_{task}_{comparison}\"\n",
    "            final_path = final_path.replace(\"#\", \"num\")\n",
    "            final_path = final_path.replace(\" \", \"_\")\n",
    "            final_path = final_path.replace(\".\", \"\")\n",
    "            final_path += \".png\"\n",
    "            plot_heatmap(overlap_df, title=f\"Feature set overlap - {comparison}\", save_path=final_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_feature_overlap_across_tasks_3way(\n",
    "        task_list,\n",
    "        version_num, \n",
    "        max_examples,\n",
    "        submod_layer,\n",
    "        node_threshold=0.1, \n",
    "        ckpt_num=20, \n",
    "        top_k=100,\n",
    "        effects_k='m0_layer12_out'\n",
    "    ):\n",
    "    lang2fidset = {}\n",
    "    lang2relie = {}\n",
    "    fid2relie = {}\n",
    "    fid2reldec = {}\n",
    "        \n",
    "    # (1) for all tasks in task_list\n",
    "    for task in task_list:\n",
    "        # (1.1) Load IE & Rel IE for all tasks in task_list\n",
    "        base_dir = \"./workspace/logs/ie_dicts_zeroshot\"\n",
    "        save_dir = f\"{base_dir}/{version_num}\"\n",
    "        final_path = f\"{save_dir}/{task}_ckpt{ckpt_num}_thresh{node_threshold}_n{max_examples}.pt\"\n",
    "        effects = torch.load(final_path)\n",
    "        \n",
    "        # (1.2) Make a dict of task -> feat_id set\n",
    "        csv_path = f\"{save_dir}/latents_{task}_ckpt{ckpt_num}_thresh{node_threshold}_n{max_examples}_topk10.csv\"\n",
    "        featdf = pd.read_csv(csv_path)\n",
    "        lang = task.split(\"_\")[1]\n",
    "        fid2relie.update(dict(zip(f\"{lang}-\" + str(featdf['feat_id']), featdf['rel_ie_class'])))\n",
    "        fid2reldec.update(dict(zip(f\"{lang}-\" + str(featdf['feat_id']), featdf['rel_dec_norm_class'])))\n",
    "        \n",
    "        all_top100_fids = set(\n",
    "            torch.topk(effects[effects_k].abs(), k=top_k).indices.tolist()\n",
    "        )\n",
    "        print(f\"# of feats for both models for {task}: \", len(all_top100_fids))\n",
    "        \n",
    "        lang2fidset[lang] = all_top100_fids\n",
    "    \n",
    "    fid2langset = defaultdict(set)\n",
    "    for lang, fidset in lang2fidset.items():\n",
    "        for fid in fidset:\n",
    "            fid2langset[fid].add(lang)\n",
    "    \n",
    "    fid2multilangscore = {}\n",
    "    for fid, langset in fid2langset.items():\n",
    "        fid2multilangscore[fid] = len(langset)\n",
    "    \n",
    "    multilangscore_mean = np.array([len(langset) for fid, langset in fid2langset.items()]).mean()\n",
    "    # print(\"Mean: \", multilangscore_mean)\n",
    "    multilangscore_std = np.array([len(langset) for fid, langset in fid2langset.items()]).std()\n",
    "    # print(\"Std: \", multilangscore_std)\n",
    "    \n",
    "    comparison = featdf[\"comparison\"].unique().tolist()[0]\n",
    "    \n",
    "    return lang2fidset, comparison\n",
    "\n",
    "def make_overlap_df(lang2fid, normalize=True):\n",
    "    langs = sorted(lang2fid)\n",
    "    if \"fra\" in langs:\n",
    "        langs = [\"arb\", \"hin\", \"fra\", \"eng\", \"spa\", \"por\"]\n",
    "    else:\n",
    "        langs = [\"arb\", \"hin\", \"por\"]\n",
    "    mat = np.zeros((len(langs), len(langs)), dtype=float)\n",
    "    for i, la in enumerate(langs):\n",
    "        for j, lb in enumerate(langs):\n",
    "            inter = lang2fid[la] & lang2fid[lb]\n",
    "            if normalize:\n",
    "                union = lang2fid[la] | lang2fid[lb]\n",
    "                mat[i, j] = len(inter) / len(union) if union else 0.0\n",
    "            else:\n",
    "                mat[i, j] = len(inter)\n",
    "    return pd.DataFrame(mat, index=langs, columns=langs)\n",
    "\n",
    "def plot_heatmap(df, top_k, title=None, save_path=None, fontsize=16):\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    im = ax.imshow(df.values, aspect='equal', vmin=0, vmax=top_k)\n",
    "    ax.set_xticks(range(len(df.columns)))\n",
    "    ax.set_xticklabels(df.columns, rotation=45, ha='right', fontsize=fontsize)\n",
    "    ax.set_yticks(range(len(df.index)))\n",
    "    ax.set_yticklabels(df.index, fontsize=fontsize)\n",
    "    cbar = fig.colorbar(im, ax=ax)\n",
    "    cbar.set_label('Feature count')\n",
    "    thresh = df.values.max() / 2.0\n",
    "    for i in range(len(df)):\n",
    "        for j in range(len(df)):\n",
    "            val = df.values[i, j]\n",
    "            text_color = \"white\" if val < thresh else \"black\"\n",
    "            ax.text(\n",
    "                j, i, f\"{int(val)}\",\n",
    "                ha='center', va='center',\n",
    "                color=text_color,\n",
    "                fontsize=fontsize\n",
    "            )\n",
    "    if title:\n",
    "        ax.set_title(title, fontsize=fontsize + 2)\n",
    "    plt.tight_layout()\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "langs=[\"eng\", \"fra\", \"spa\", \"por\", \"arb\", \"hin\"]\n",
    "svg_langs=[\"por\", \"arb\", \"hin\"]\n",
    "\n",
    "tasks=[\"SV-#\", \"SV-G\", \"SV-P\"]\n",
    "task2len = {\n",
    "    \"SV-#\": 100,\n",
    "    \"SV-G\": 100, \n",
    "    \"SV-P\": 290\n",
    "}\n",
    "\n",
    "for top_k in [10, 100]:\n",
    "    for task in tasks:\n",
    "        print(\"#\" * 40)\n",
    "        print(\"task: \", task)\n",
    "        for version_num in [\"454\"]:\n",
    "            print(\"-\" * 20)\n",
    "            print(\"version_num: \", version_num)\n",
    "            effects_k_list = ['m0_layer12_out', 'm1_layer12_out', 'm2_layer12_out']\n",
    "            for i, effects_k in enumerate(effects_k_list):\n",
    "                print(\"-\" * 20)\n",
    "                print(\"effects_k: \", effects_k)\n",
    "                if task == \"SV-G\":\n",
    "                    task_list = [f\"multiblimp_{lang}_{task}\" for lang in svg_langs]\n",
    "                else:\n",
    "                    task_list = [f\"multiblimp_{lang}_{task}\" for lang in langs]\n",
    "                lang2fid, comparison = get_feature_overlap_across_tasks_3way(\n",
    "                    task_list=task_list,\n",
    "                    version_num=\"version_\" + version_num,\n",
    "                    max_examples=task2len[task],\n",
    "                    submod_layer=12,\n",
    "                    top_k=top_k,\n",
    "                    effects_k=effects_k\n",
    "                )\n",
    "                \n",
    "                overlap_df = make_overlap_df(lang2fid, normalize=False)\n",
    "                checkpoint_name = comparison.split(\" vs. \")[i]\n",
    "                \n",
    "                final_path = f\"figs/multilingual_overlap_3way/multilang_overlap_topk{top_k}_{task}_{i}\"\n",
    "                final_path = final_path.replace(\"#\", \"num\")\n",
    "                final_path = final_path.replace(\" \", \"_\")\n",
    "                final_path = final_path.replace(\".\", \"\")\n",
    "                final_path += \".png\"            \n",
    "                plot_heatmap(overlap_df, top_k=top_k, title=f\"Feature set overlap - {checkpoint_name}\", save_path=final_path)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotation Table Pythia 3-way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = table_generator_three_way(\n",
    "    version_num    = 446,\n",
    "    model_name     = \"Pythia-1B\"\n",
    ")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotation Table OLMo 3-way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = table_generator_three_way(\n",
    "    version_num    = 447,\n",
    "    model_name     = \"OLMo-1B\"\n",
    ")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotation Table BLOOM 3-way (CLAMS & MultiBLiMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task_name in [\"clams_fraeng\", \"multiblimp_eng\", \"multiblimp_fra\", \"multiblimp_hin\"]:\n",
    "    out = table_generator_three_way_bloom(\n",
    "        annotation_filename = f\"annotation_{task_name}.csv\",\n",
    "        version_num         = 454,\n",
    "        model_name          = \"BLOOM-1B\"\n",
    "    )\n",
    "    print(out)\n",
    "    print(\"\\n\\n\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotation Table Pythia 2-way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = table_generator_two_way(\n",
    "    annotation_filename = f\"workspace/annotation_pythia_2way_blimp.csv\",\n",
    "    model_name          = \"Pythia-1B\"\n",
    ")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotation Table BLOOM 2-way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = table_generator_two_way_bloom(\n",
    "    annotation_filename = f\"workspace/annotation_bloom_2way_clamsfraeng.csv\",\n",
    "    model_name          = \"BLOOM-1B\"\n",
    ")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RelIE & RelDec Corr with Delta M1 Patch / Delta M2 Patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_scatter(df, x_col, y_col):\n",
    "    x = df[x_col]\n",
    "    y = df[y_col]\n",
    "    \n",
    "    # compute z-scores for y\n",
    "    z_scores = stats.zscore(y)\n",
    "    abs_z = abs(z_scores)\n",
    "\n",
    "    # filter (e.g. keep only |z| < 3)\n",
    "    df = df[abs_z < 3]\n",
    "    \n",
    "    x = df[x_col]\n",
    "    y = df[y_col]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(x, y)\n",
    "    plt.xlabel(x_col)\n",
    "    plt.ylabel(y_col)\n",
    "    plt.ylim(0,10)\n",
    "    plt.title(f'{y_col} vs {x_col}')\n",
    "    plt.show()\n",
    "\n",
    "def gather_corr_results(top_k, version_list, model_name, do_corr_plot=False):\n",
    "    base_dir = \"./workspace/logs/ie_dicts_zeroshot\"\n",
    "    subtasks = [\n",
    "        \"distractor_agreement_relational_noun\",\n",
    "        \"distractor_agreement_relative_clause\",\n",
    "        \"irregular_plural_subject_verb_agreement_1\",\n",
    "        \"regular_plural_subject_verb_agreement_1\"\n",
    "    ]\n",
    "    subtask2name = {\n",
    "        \"subjectverb-distractor_agreement_relational_noun\": \"\\\\texttt{Distractor Relational Noun}\",\n",
    "        \"subjectverb-distractor_agreement_relative_clause\": \"\\\\texttt{Distractor Relative Clause}\",\n",
    "        \"subjectverb-irregular_plural_subject_verb_agreement_1\": \"\\\\texttt{Irregular Plural Subject}\",\n",
    "        \"subjectverb-regular_plural_subject_verb_agreement_1\": \"\\\\texttt{Regular Plural Subject}\",\n",
    "        \n",
    "    }\n",
    "    \n",
    "    # Collect DataFrames in a list, then concatenate\n",
    "    all_dfs = []\n",
    "    plt_cnt = 0\n",
    "    for version_num in version_list:\n",
    "        save_dir = os.path.join(base_dir, \"version_\" + str(version_num))\n",
    "        for subtask in subtasks:\n",
    "            corr_path = os.path.join(\n",
    "                save_dir,\n",
    "                f\"ablation-task_subjectverb-{subtask}-topk{top_k}-corr.csv\"\n",
    "            )\n",
    "            if os.path.isfile(corr_path):\n",
    "                df = pd.read_csv(corr_path)\n",
    "                all_dfs.append(df)\n",
    "            else:\n",
    "                print(f\"Warning: file not found: {corr_path}\")\n",
    "            \n",
    "            if do_corr_plot and plt_cnt < 2:\n",
    "                summary_path = os.path.join(\n",
    "                    save_dir,\n",
    "                    f\"ablation-task_subjectverb-{subtask}-topk{top_k}-deltasummary.csv\"\n",
    "                )\n",
    "                if os.path.isfile(corr_path):\n",
    "                    summary_df = pd.read_csv(summary_path)\n",
    "                    clean_scatter(df=summary_df, y_col=\"LogProbDiff Δ Ratio Abs(M2/M1)\", x_col=\"RelDec\")\n",
    "                    clean_scatter(df=summary_df, y_col=\"LogProbDiff Δ Ratio Abs(M2/M1)\", x_col=\"RelIE\")\n",
    "                    plt_cnt += 1\n",
    "                else:\n",
    "                    print(f\"Warning: file not found: {corr_path}\")\n",
    "\n",
    "    # Concatenate all (will append rows)\n",
    "    if all_dfs:\n",
    "        combined = pd.concat(all_dfs, ignore_index=True)\n",
    "        combined[\"task\"] = combined[\"task\"].replace(subtask2name)\n",
    "        combined = combined[['comparison', 'task', 'rho(Δ Ratio Abs(M2/M1) - RelDec)',\n",
    "       'rho(Δ Ratio Abs(M2/M1) - RelIE)']]\n",
    "        \n",
    "        # write out a single CSV\n",
    "        output_path = os.path.join(\".\",  \"workspace\", \"results\", f\"combined_ablation_corr_{model_name}_topk{top_k}.csv\")\n",
    "        combined.to_csv(output_path, index=False)\n",
    "        print(f\"Combined CSV written to: {output_path}\")\n",
    "        \n",
    "        # write out a single LaTeX\n",
    "        num_cols = [\n",
    "            'rho(Δ Ratio Abs(M2/M1) - RelDec)',\n",
    "            'rho(Δ Ratio Abs(M2/M1) - RelIE)'\n",
    "        ]\n",
    "        \n",
    "        group_means = (\n",
    "            combined\n",
    "            .groupby('comparison')[num_cols]\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "        )\n",
    "        # label them\n",
    "        group_means['comparison'] = 'Avg ' + group_means['comparison']\n",
    "        group_means['task'] = '-'\n",
    "        # make sure columns are in the same order\n",
    "        group_means = group_means[['comparison', 'task'] + num_cols]\n",
    "\n",
    "        # compute overall average\n",
    "        overall = combined[num_cols].mean().to_frame().T\n",
    "        overall['comparison'] = 'Avg'\n",
    "        overall['task'] = '-'\n",
    "        overall = overall[['comparison','task'] + num_cols]\n",
    "        \n",
    "        final = pd.concat([combined, group_means, overall], ignore_index=True)\n",
    "        print(final.to_latex(index=False, float_format=\"%.3f\"))\n",
    "    else:\n",
    "        print(\"No CSV files were loaded. Check your paths.\")\n",
    "        \n",
    "gather_corr_results(top_k=10, version_list=[218, 265, 219], model_name=\"pythia\", do_corr_plot=False)\n",
    "gather_corr_results(top_k=10, version_list=\"440 430 434 433 436\".split(\" \"), model_name=\"olmo\", do_corr_plot=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
